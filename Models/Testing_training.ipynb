{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HjW4CHbRNq",
        "outputId": "e89ddcc8-faf8-4c36-ab67-1e172783e8a1"
      },
      "outputs": [],
      "source": [
        "#!pip install matplotlib\n",
        "#!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "urVnsyjGbbII"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM-0qb4MvtJN"
      },
      "source": [
        "#  Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDk8VGP32SDx",
        "outputId": "06fa4d5f-104d-4b02-bb77-6abe7154e257"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Directory to check for existence\n",
        "train_dir = '../train'\n",
        "# Directory to check for existence\n",
        "valid_dir = '../valid'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ofuu8rlg2eIa"
      },
      "outputs": [],
      "source": [
        "height,width=180,180\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Augment the data\n",
        "#data_augmentation = tf.keras.Sequential([\n",
        "#    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "#    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "#    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "#    tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
        "#    tf.keras.layers.experimental.preprocessing.RandomTranslation(\n",
        "#        height_factor=0.2, \n",
        "#        width_factor=0.2, \n",
        "#        fill_mode='reflect'\n",
        "#    ),\n",
        "#])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXnhnIlC2gT5",
        "outputId": "43a41223-6b38-4147-a897-637d72c0dd82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 81946 files belonging to 10 classes.\n",
            "Found 10244 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "#train_set = tf.keras.preprocessing.image_dataset_from_directory(train_dir,image_size=(height,width))\n",
        "#valid_set = tf.keras.preprocessing.image_dataset_from_directory(valid_dir,image_size=(height,width))\n",
        "\n",
        "\n",
        "\n",
        "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(height, width),\n",
        "    shuffle=True,\n",
        ")\n",
        "class_names = train_set.class_names\n",
        "#train_set = train_set.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    image_size=(height, width),\n",
        ")\n",
        "\n",
        "batches = 10\n",
        "train_set = train_set.take(batches)\n",
        "valid_set = valid_set.take(batches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m5QE94f2jCB",
        "outputId": "18aaadcc-fd59-4e71-f858-0226282052cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10244 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_set = tf.keras.preprocessing.image_dataset_from_directory(valid_dir,image_size=(height,width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.layers import Dense, Flatten\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create sequential model and download weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 25s 1s/step - loss: 9590.3555 - accuracy: 0.1156 - val_loss: 1518.0831 - val_accuracy: 0.2259\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 25s 1s/step - loss: 443.2111 - accuracy: 0.3703 - val_loss: 57.7588 - val_accuracy: 0.3708\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 27s 1s/step - loss: 13.9070 - accuracy: 0.7250 - val_loss: 37.3726 - val_accuracy: 0.3914\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 25s 1s/step - loss: 5.3668 - accuracy: 0.8531 - val_loss: 25.9697 - val_accuracy: 0.4610\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 25s 1s/step - loss: 1.9982 - accuracy: 0.9281 - val_loss: 25.1817 - val_accuracy: 0.4737\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 24s 1s/step - loss: 1.0510 - accuracy: 0.9609 - val_loss: 25.7674 - val_accuracy: 0.4844\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 24s 1s/step - loss: 1.6833 - accuracy: 0.9594 - val_loss: 26.5197 - val_accuracy: 0.4705\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.7935 - accuracy: 0.9688 - val_loss: 24.7660 - val_accuracy: 0.4730\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 25s 1s/step - loss: 0.4292 - accuracy: 0.9719 - val_loss: 24.5461 - val_accuracy: 0.4799\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 24s 1s/step - loss: 0.6088 - accuracy: 0.9828 - val_loss: 24.1124 - val_accuracy: 0.4813\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# Define your model architecture\n",
        "model = Sequential([\n",
        "    # Add layers according to your requirement\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # Adjust the number of units to match the number of classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_set, validation_data=valid_set, epochs=10)\n",
        "model.save_weights('sequential.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create ResNet50 model and download weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer input_1: Trainable = False\n",
            "Layer conv1_pad: Trainable = False\n",
            "Layer conv1_conv: Trainable = False\n",
            "Layer conv1_bn: Trainable = False\n",
            "Layer conv1_relu: Trainable = False\n",
            "Layer pool1_pad: Trainable = False\n",
            "Layer pool1_pool: Trainable = False\n",
            "Layer conv2_block1_1_conv: Trainable = False\n",
            "Layer conv2_block1_1_bn: Trainable = False\n",
            "Layer conv2_block1_1_relu: Trainable = False\n",
            "Layer conv2_block1_2_conv: Trainable = False\n",
            "Layer conv2_block1_2_bn: Trainable = False\n",
            "Layer conv2_block1_2_relu: Trainable = False\n",
            "Layer conv2_block1_0_conv: Trainable = False\n",
            "Layer conv2_block1_3_conv: Trainable = False\n",
            "Layer conv2_block1_0_bn: Trainable = False\n",
            "Layer conv2_block1_3_bn: Trainable = False\n",
            "Layer conv2_block1_add: Trainable = False\n",
            "Layer conv2_block1_out: Trainable = False\n",
            "Layer conv2_block2_1_conv: Trainable = False\n",
            "Layer conv2_block2_1_bn: Trainable = False\n",
            "Layer conv2_block2_1_relu: Trainable = False\n",
            "Layer conv2_block2_2_conv: Trainable = False\n",
            "Layer conv2_block2_2_bn: Trainable = False\n",
            "Layer conv2_block2_2_relu: Trainable = False\n",
            "Layer conv2_block2_3_conv: Trainable = False\n",
            "Layer conv2_block2_3_bn: Trainable = False\n",
            "Layer conv2_block2_add: Trainable = False\n",
            "Layer conv2_block2_out: Trainable = False\n",
            "Layer conv2_block3_1_conv: Trainable = False\n",
            "Layer conv2_block3_1_bn: Trainable = False\n",
            "Layer conv2_block3_1_relu: Trainable = False\n",
            "Layer conv2_block3_2_conv: Trainable = False\n",
            "Layer conv2_block3_2_bn: Trainable = False\n",
            "Layer conv2_block3_2_relu: Trainable = False\n",
            "Layer conv2_block3_3_conv: Trainable = False\n",
            "Layer conv2_block3_3_bn: Trainable = False\n",
            "Layer conv2_block3_add: Trainable = False\n",
            "Layer conv2_block3_out: Trainable = False\n",
            "Layer conv3_block1_1_conv: Trainable = False\n",
            "Layer conv3_block1_1_bn: Trainable = False\n",
            "Layer conv3_block1_1_relu: Trainable = False\n",
            "Layer conv3_block1_2_conv: Trainable = False\n",
            "Layer conv3_block1_2_bn: Trainable = False\n",
            "Layer conv3_block1_2_relu: Trainable = False\n",
            "Layer conv3_block1_0_conv: Trainable = False\n",
            "Layer conv3_block1_3_conv: Trainable = False\n",
            "Layer conv3_block1_0_bn: Trainable = False\n",
            "Layer conv3_block1_3_bn: Trainable = False\n",
            "Layer conv3_block1_add: Trainable = False\n",
            "Layer conv3_block1_out: Trainable = False\n",
            "Layer conv3_block2_1_conv: Trainable = False\n",
            "Layer conv3_block2_1_bn: Trainable = False\n",
            "Layer conv3_block2_1_relu: Trainable = False\n",
            "Layer conv3_block2_2_conv: Trainable = False\n",
            "Layer conv3_block2_2_bn: Trainable = False\n",
            "Layer conv3_block2_2_relu: Trainable = False\n",
            "Layer conv3_block2_3_conv: Trainable = False\n",
            "Layer conv3_block2_3_bn: Trainable = False\n",
            "Layer conv3_block2_add: Trainable = False\n",
            "Layer conv3_block2_out: Trainable = False\n",
            "Layer conv3_block3_1_conv: Trainable = False\n",
            "Layer conv3_block3_1_bn: Trainable = False\n",
            "Layer conv3_block3_1_relu: Trainable = False\n",
            "Layer conv3_block3_2_conv: Trainable = False\n",
            "Layer conv3_block3_2_bn: Trainable = False\n",
            "Layer conv3_block3_2_relu: Trainable = False\n",
            "Layer conv3_block3_3_conv: Trainable = False\n",
            "Layer conv3_block3_3_bn: Trainable = False\n",
            "Layer conv3_block3_add: Trainable = False\n",
            "Layer conv3_block3_out: Trainable = False\n",
            "Layer conv3_block4_1_conv: Trainable = False\n",
            "Layer conv3_block4_1_bn: Trainable = False\n",
            "Layer conv3_block4_1_relu: Trainable = False\n",
            "Layer conv3_block4_2_conv: Trainable = False\n",
            "Layer conv3_block4_2_bn: Trainable = False\n",
            "Layer conv3_block4_2_relu: Trainable = False\n",
            "Layer conv3_block4_3_conv: Trainable = False\n",
            "Layer conv3_block4_3_bn: Trainable = False\n",
            "Layer conv3_block4_add: Trainable = False\n",
            "Layer conv3_block4_out: Trainable = False\n",
            "Layer conv4_block1_1_conv: Trainable = False\n",
            "Layer conv4_block1_1_bn: Trainable = False\n",
            "Layer conv4_block1_1_relu: Trainable = False\n",
            "Layer conv4_block1_2_conv: Trainable = False\n",
            "Layer conv4_block1_2_bn: Trainable = False\n",
            "Layer conv4_block1_2_relu: Trainable = False\n",
            "Layer conv4_block1_0_conv: Trainable = False\n",
            "Layer conv4_block1_3_conv: Trainable = False\n",
            "Layer conv4_block1_0_bn: Trainable = False\n",
            "Layer conv4_block1_3_bn: Trainable = False\n",
            "Layer conv4_block1_add: Trainable = False\n",
            "Layer conv4_block1_out: Trainable = False\n",
            "Layer conv4_block2_1_conv: Trainable = False\n",
            "Layer conv4_block2_1_bn: Trainable = False\n",
            "Layer conv4_block2_1_relu: Trainable = False\n",
            "Layer conv4_block2_2_conv: Trainable = False\n",
            "Layer conv4_block2_2_bn: Trainable = False\n",
            "Layer conv4_block2_2_relu: Trainable = False\n",
            "Layer conv4_block2_3_conv: Trainable = False\n",
            "Layer conv4_block2_3_bn: Trainable = False\n",
            "Layer conv4_block2_add: Trainable = False\n",
            "Layer conv4_block2_out: Trainable = False\n",
            "Layer conv4_block3_1_conv: Trainable = False\n",
            "Layer conv4_block3_1_bn: Trainable = False\n",
            "Layer conv4_block3_1_relu: Trainable = False\n",
            "Layer conv4_block3_2_conv: Trainable = False\n",
            "Layer conv4_block3_2_bn: Trainable = False\n",
            "Layer conv4_block3_2_relu: Trainable = False\n",
            "Layer conv4_block3_3_conv: Trainable = False\n",
            "Layer conv4_block3_3_bn: Trainable = False\n",
            "Layer conv4_block3_add: Trainable = False\n",
            "Layer conv4_block3_out: Trainable = False\n",
            "Layer conv4_block4_1_conv: Trainable = False\n",
            "Layer conv4_block4_1_bn: Trainable = False\n",
            "Layer conv4_block4_1_relu: Trainable = False\n",
            "Layer conv4_block4_2_conv: Trainable = False\n",
            "Layer conv4_block4_2_bn: Trainable = False\n",
            "Layer conv4_block4_2_relu: Trainable = False\n",
            "Layer conv4_block4_3_conv: Trainable = False\n",
            "Layer conv4_block4_3_bn: Trainable = False\n",
            "Layer conv4_block4_add: Trainable = False\n",
            "Layer conv4_block4_out: Trainable = False\n",
            "Layer conv4_block5_1_conv: Trainable = False\n",
            "Layer conv4_block5_1_bn: Trainable = False\n",
            "Layer conv4_block5_1_relu: Trainable = False\n",
            "Layer conv4_block5_2_conv: Trainable = False\n",
            "Layer conv4_block5_2_bn: Trainable = False\n",
            "Layer conv4_block5_2_relu: Trainable = False\n",
            "Layer conv4_block5_3_conv: Trainable = False\n",
            "Layer conv4_block5_3_bn: Trainable = False\n",
            "Layer conv4_block5_add: Trainable = False\n",
            "Layer conv4_block5_out: Trainable = False\n",
            "Layer conv4_block6_1_conv: Trainable = False\n",
            "Layer conv4_block6_1_bn: Trainable = False\n",
            "Layer conv4_block6_1_relu: Trainable = False\n",
            "Layer conv4_block6_2_conv: Trainable = False\n",
            "Layer conv4_block6_2_bn: Trainable = False\n",
            "Layer conv4_block6_2_relu: Trainable = False\n",
            "Layer conv4_block6_3_conv: Trainable = False\n",
            "Layer conv4_block6_3_bn: Trainable = False\n",
            "Layer conv4_block6_add: Trainable = False\n",
            "Layer conv4_block6_out: Trainable = False\n",
            "Layer conv5_block1_1_conv: Trainable = False\n",
            "Layer conv5_block1_1_bn: Trainable = False\n",
            "Layer conv5_block1_1_relu: Trainable = False\n",
            "Layer conv5_block1_2_conv: Trainable = False\n",
            "Layer conv5_block1_2_bn: Trainable = False\n",
            "Layer conv5_block1_2_relu: Trainable = False\n",
            "Layer conv5_block1_0_conv: Trainable = False\n",
            "Layer conv5_block1_3_conv: Trainable = False\n",
            "Layer conv5_block1_0_bn: Trainable = False\n",
            "Layer conv5_block1_3_bn: Trainable = False\n",
            "Layer conv5_block1_add: Trainable = False\n",
            "Layer conv5_block1_out: Trainable = False\n",
            "Layer conv5_block2_1_conv: Trainable = False\n",
            "Layer conv5_block2_1_bn: Trainable = False\n",
            "Layer conv5_block2_1_relu: Trainable = False\n",
            "Layer conv5_block2_2_conv: Trainable = False\n",
            "Layer conv5_block2_2_bn: Trainable = False\n",
            "Layer conv5_block2_2_relu: Trainable = False\n",
            "Layer conv5_block2_3_conv: Trainable = False\n",
            "Layer conv5_block2_3_bn: Trainable = False\n",
            "Layer conv5_block2_add: Trainable = False\n",
            "Layer conv5_block2_out: Trainable = False\n",
            "Layer conv5_block3_1_conv: Trainable = False\n",
            "Layer conv5_block3_1_bn: Trainable = False\n",
            "Layer conv5_block3_1_relu: Trainable = False\n",
            "Layer conv5_block3_2_conv: Trainable = False\n",
            "Layer conv5_block3_2_bn: Trainable = False\n",
            "Layer conv5_block3_2_relu: Trainable = False\n",
            "Layer conv5_block3_3_conv: Trainable = False\n",
            "Layer conv5_block3_3_bn: Trainable = False\n",
            "Layer conv5_block3_add: Trainable = False\n",
            "Layer conv5_block3_out: Trainable = False\n",
            "Layer avg_pool: Trainable = False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/EdenChung/anaconda3/envs/ml/lib/python3.9/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "dnn_model = Sequential()\n",
        "\n",
        "imported_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3),\n",
        "    pooling='avg',\n",
        "    classes=10,\n",
        "    weights='imagenet')\n",
        "\n",
        "# Freeze all layers in the imported model\n",
        "for layer in imported_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Check if the layers are trainable\n",
        "for layer in imported_model.layers:\n",
        "    print(f\"Layer {layer.name}: Trainable = {layer.trainable}\")\n",
        "\n",
        "\n",
        "dnn_model.add(imported_model)\n",
        "dnn_model.add(Flatten())\n",
        "#dnn_model.add(Dense(600, activation='relu'))\n",
        "#could go back to 600 later\n",
        "dnn_model.add(Dense(256, activation='relu'))\n",
        "dnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "dnn_model.compile(optimizer=Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the resnet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 11s 996ms/step - loss: 1.8338 - accuracy: 0.4437 - val_loss: 1.1433 - val_accuracy: 0.5625\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 10s 976ms/step - loss: 0.6189 - accuracy: 0.7750 - val_loss: 0.7111 - val_accuracy: 0.7344\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 10s 979ms/step - loss: 0.4160 - accuracy: 0.8531 - val_loss: 0.5352 - val_accuracy: 0.8094\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 10s 989ms/step - loss: 0.1918 - accuracy: 0.9438 - val_loss: 0.5052 - val_accuracy: 0.8062\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.1854 - accuracy: 0.9438 - val_loss: 0.5094 - val_accuracy: 0.8250\n"
          ]
        }
      ],
      "source": [
        "history = dnn_model.fit(\n",
        "train_set,\n",
        "validation_data=valid_set,\n",
        "epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nj1i4Q4j73VZ"
      },
      "outputs": [],
      "source": [
        "dnn_model.save_weights('resnet_no_augmentation_full_dataset_epochs10.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VGG Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "vgg_model = Sequential()\n",
        "\n",
        "imported_model = tf.keras.applications.VGG19(\n",
        "    include_top=False,  # Do not include the top (fully connected) layers\n",
        "    input_shape=(180, 180, 3),  # VGG19 default input size is 224x224\n",
        "    pooling='avg',  # Add global average pooling\n",
        "    weights='imagenet'  # Use weights pre-trained on ImageNet\n",
        ")\n",
        "\n",
        "for layer in imported_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "vgg_model.add(imported_model)\n",
        "vgg_model.add(Flatten())\n",
        "vgg_model.add(Dense(256, activation='relu'))\n",
        "vgg_model.add(Dense(10, activation='softmax'))  # Adjust the number of units according to your task\n",
        "\n",
        "vgg_model.compile(\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0243 - accuracy: 0.5688 - val_loss: 1.7145 - val_accuracy: 0.5781\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 33s 3s/step - loss: 0.7088 - accuracy: 0.8062 - val_loss: 1.1874 - val_accuracy: 0.7250\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 32s 3s/step - loss: 0.3845 - accuracy: 0.8813 - val_loss: 0.9531 - val_accuracy: 0.7531\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 33s 3s/step - loss: 0.3021 - accuracy: 0.9125 - val_loss: 1.0913 - val_accuracy: 0.7188\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 32s 3s/step - loss: 0.1389 - accuracy: 0.9531 - val_loss: 0.9782 - val_accuracy: 0.7656\n"
          ]
        }
      ],
      "source": [
        "history = vgg_model.fit(\n",
        "train_set,\n",
        "validation_data=valid_set,\n",
        "epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EfficientNetV2S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image, label):\n",
        "    resized_image = tf.image.resize(image, [384, 384])  # Resize to the expected input size\n",
        "    return resized_image, label\n",
        "\n",
        "# Assuming `train_dataset` and `valid_dataset` are your original datasets\n",
        "train_dataset_resized = train_set.map(preprocess_image)\n",
        "valid_dataset_resized = valid_set.map(preprocess_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/EdenChung/anaconda3/envs/ml/lib/python3.9/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "# Load the EfficientNetV2S model with a custom input size\n",
        "efficient_net = tf.keras.applications.EfficientNetV2S(\n",
        "    include_top=True,  # Include the fully connected layer at the top\n",
        "    weights=\"imagenet\",  # Use weights pre-trained on ImageNet\n",
        "    input_tensor=None,  # Optional custom input tensor\n",
        "    input_shape=None,  # Automatically adapts to the input shape of the weights\n",
        "    pooling=None,  # No additional pooling layer at the top\n",
        "    classes=1000,  # Number of classes for the ImageNet dataset\n",
        "    classifier_activation=\"softmax\",  # Use softmax activation for the final layer\n",
        "    include_preprocessing=True  # Include preprocessing according to the model's requirements\n",
        ")\n",
        "\n",
        "efficient_net.compile(\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 102s 10s/step - loss: 2.8147 - accuracy: 0.5656 - val_loss: 1.5411 - val_accuracy: 0.7531\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 95s 10s/step - loss: 0.5462 - accuracy: 0.8594 - val_loss: 0.8403 - val_accuracy: 0.8313\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 109s 11s/step - loss: 0.5167 - accuracy: 0.8813 - val_loss: 0.4979 - val_accuracy: 0.8594\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 108s 11s/step - loss: 0.3889 - accuracy: 0.8938 - val_loss: 0.8952 - val_accuracy: 0.8375\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 109s 11s/step - loss: 0.5691 - accuracy: 0.8813 - val_loss: 0.5980 - val_accuracy: 0.8438\n"
          ]
        }
      ],
      "source": [
        "history = efficient_net.fit(\n",
        "train_dataset_resized,\n",
        "validation_data=valid_dataset_resized,\n",
        "epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
