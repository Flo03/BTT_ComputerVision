{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constucturing The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "urVnsyjGbbII"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "height,width=180,180\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recreate the model and load the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/EdenChung/anaconda3/envs/ml/lib/python3.9/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "# Load the EfficientNetV2S model without the top layer\n",
        "base_model = tf.keras.applications.EfficientNetV2S(\n",
        "    include_top=False,  # Do not include the fully connected layer at the top\n",
        "    weights=\"imagenet\",  # Use weights pre-trained on ImageNet\n",
        "    input_tensor=None,  # Optional custom input tensor\n",
        "    input_shape=None,  # Specify your custom input shape if necessary\n",
        "    pooling=None,  # Specify this if you need a specific type of pooling\n",
        "    include_preprocessing=True  # Include preprocessing according to the model's requirements\n",
        ")\n",
        "\n",
        "# Make sure the base model is not trainable\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add a logistic layer for 10 classes\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# This is the model we will train\n",
        "efficient_net_new = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "efficient_net_new.compile(optimizer=Adam(lr=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "efficient_net_new.load_weights('efficientnet_augmentation_full_dataset_epochs30.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../test/facd4dcd8e869617.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image\u001b[39;00m\n\u001b[1;32m     24\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test\u001b[39m\u001b[38;5;124m'\u001b[39m, file_name)  \u001b[38;5;66;03m# Update with your test images path\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m     28\u001b[0m predictions \u001b[38;5;241m=\u001b[39m efficient_net_new\u001b[38;5;241m.\u001b[39mpredict(img_array)\n",
            "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path, height, width)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, height, width):\n\u001b[0;32m----> 7\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[1;32m      9\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Create a batch dimension\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/keras/src/utils/image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../test/facd4dcd8e869617.jpg'"
          ]
        }
      ],
      "source": [
        "##Creating the submission\n",
        "\n",
        "height = 384\n",
        "width = 384\n",
        "\n",
        "def preprocess_image(image_path, height, width):\n",
        "    img = image.load_img(image_path, target_size=(height, width))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create a batch dimension\n",
        "    resized_image = tf.image.resize(img_array, [384, 384])  # Resize to the expected input size\n",
        "    return resized_image\n",
        "\n",
        "#test_df = pd.read_csv('test.csv')\n",
        "test_df = pd.read_csv('../../BTTAIxNYBG-test.csv')\n",
        "\n",
        "# Initialize a list to store predictions\n",
        "predictions_list = []\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "    unique_id = row['uniqueID']\n",
        "    file_name = row['imageFile']\n",
        "    \n",
        "    # Load and preprocess the image\n",
        "    img_path = os.path.join('../../test', file_name)  # Update with your test images path\n",
        "    img_array = preprocess_image(img_path, height, width)\n",
        "    \n",
        "    # Predict\n",
        "    predictions = efficient_net_new.predict(img_array)\n",
        "    predicted_class = tf.argmax(predictions, axis=1).numpy()[0]  # Take the argmax to get the predicted class ID\n",
        "    \n",
        "    # Store the uniqueID and predicted classID\n",
        "    predictions_list.append({'uniqueID': unique_id, 'classID': predicted_class})\n",
        "\n",
        "# Convert the predictions list to a DataFrame\n",
        "predictions_df = pd.DataFrame(predictions_list)\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "predictions_df.to_csv('predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
