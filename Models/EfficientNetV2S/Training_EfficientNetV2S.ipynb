{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HjW4CHbRNq",
        "outputId": "e89ddcc8-faf8-4c36-ab67-1e172783e8a1"
      },
      "outputs": [],
      "source": [
        "#!pip install matplotlib\n",
        "#!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "urVnsyjGbbII"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM-0qb4MvtJN"
      },
      "source": [
        "#  Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDk8VGP32SDx",
        "outputId": "06fa4d5f-104d-4b02-bb77-6abe7154e257"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Directory to check for existence\n",
        "train_dir = '../../train'\n",
        "# Directory to check for existence\n",
        "valid_dir = '../../valid'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ofuu8rlg2eIa"
      },
      "outputs": [],
      "source": [
        "height,width=180,180\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_height = 180\n",
        "final_width = 180\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomTranslation(\n",
        "        height_factor=0.1, \n",
        "        width_factor=0.1, \n",
        "        fill_mode='reflect'\n",
        "    ),\n",
        "    # Resizing layer to ensure all images are of the same size\n",
        "    tf.keras.layers.experimental.preprocessing.Resizing(final_height, final_width),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXnhnIlC2gT5",
        "outputId": "43a41223-6b38-4147-a897-637d72c0dd82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 81946 files belonging to 10 classes.\n",
            "Found 10244 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(height, width),\n",
        "    shuffle=True,\n",
        ")\n",
        "class_names = train_set.class_names\n",
        "#train_set = train_set.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    image_size=(height, width),\n",
        ")\n",
        "\n",
        "\n",
        "#batches = 20\n",
        "#train_set = train_set.take(batches)\n",
        "#valid_set = valid_set.take(batches)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 81946 files belonging to 10 classes.\n",
            "Found 10244 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(height, width),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "valid_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    image_size=(height, width),\n",
        "    batch_size=batch_size  # Keep validation batch size the same for consistency\n",
        ")\n",
        "\n",
        "train_set = train_set.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "train_set = train_set.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "valid_set = valid_set.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m5QE94f2jCB",
        "outputId": "18aaadcc-fd59-4e71-f858-0226282052cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10244 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_set = tf.keras.preprocessing.image_dataset_from_directory(valid_dir,image_size=(height,width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/EdenChung/anaconda3/envs/ml/lib/python3.9/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "# Load the EfficientNetV2S model without the top layer\n",
        "base_model = tf.keras.applications.EfficientNetV2S(\n",
        "    include_top=False,  # Do not include the fully connected layer at the top\n",
        "    weights=\"imagenet\",  # Use weights pre-trained on ImageNet\n",
        "    input_tensor=None,  # Optional custom input tensor\n",
        "    input_shape=None,  # Specify your custom input shape if necessary\n",
        "    pooling=None,  # Specify this if you need a specific type of pooling\n",
        "    include_preprocessing=True  # Include preprocessing according to the model's requirements\n",
        ")\n",
        "\n",
        "# Make sure the base model is not trainable\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add a logistic layer for 10 classes\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# This is the model we will train\n",
        "efficient_net_new = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "efficient_net_new.compile(optimizer=Adam(lr=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image, label):\n",
        "    resized_image = tf.image.resize(image, [384, 384])  # Resize to the expected input size\n",
        "    return resized_image, label\n",
        "\n",
        "# Assuming `train_dataset` and `valid_dataset` are your original datasets\n",
        "train_dataset_resized = train_set.map(preprocess_image)\n",
        "valid_dataset_resized = valid_set.map(preprocess_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor the validation loss\n",
        "    min_delta=0.001,  # Minimum change to qualify as an improvement\n",
        "    patience=2,  # Stop after 10 epochs without improvement\n",
        "    verbose=1,  # Print a message when stopping\n",
        "    mode='min',  # Minimize the monitored quantity (val_loss)\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "\n",
        "# Train the model with the early stopping callback\n",
        "history = efficient_net_new.fit(\n",
        "    train_set,\n",
        "    epochs=10,  # Example number of epochs\n",
        "    validation_data=valid_set,\n",
        "    callbacks=[early_stopping]  # Add early stopping to the list of callbacks\n",
        ")\n",
        "\n",
        "efficient_net_new.save_weights('efficientnet_augmentation_full_dataset_epochs10.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
